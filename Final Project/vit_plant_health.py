# -*- coding: utf-8 -*-
"""ViT_plant_health.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bl3iLPAZSh6-I3BALHPC5kP8TGY_2k4a

##Set-up environment
Firstly, install Transformers as well as Datasets.
"""

!pip install -q git+https://github.com/huggingface/transformers.git

"""Change the transformers version because the newest one is not stable for this model."""

!pip install transformers==4.30.0

!pip install -q datasets

"""##Load the image classfication dataset

Load the plant health condition dataset from hugging face.
"""

from datasets import load_dataset

ds = load_dataset("timm/plant-pathology-2021")

"""##Create smaller dataset for fine-tuning

I create a small image classification dataset by selecting about 1% from the huge plant health dataset, which should contains only about hundreds of images with only one type of health condition each.
"""

small_train = ds['train'].train_test_split(test_size=0.01, seed=42)['test']
validation_test_split = ds["validation"].train_test_split(test_size=0.1, seed=42)["test"].train_test_split(test_size=0.5, seed=42)
small_validation = validation_test_split['train']
small_test = validation_test_split['test']

# Filter dataset to include only images with a single label
def filter_single_label(example):
    return len(example["label_names"]) == 1  # Only keep examples with one label

small_train = small_train.filter(filter_single_label)
small_validation = small_validation.filter(filter_single_label)
small_test = small_test.filter(filter_single_label)

# Confirm sizes
print(f"Train examples: {len(small_train)}")
print(f"New Validation Size: {len(small_validation)}")
print(f"Test Size: {len(small_test)}")

"""The "labels" column should be converted to integer because it is in the form of "[1]"."""

def parse_label(label):
    return label[0]  # Extract the first element if it's a list

small_train = small_train.map(lambda x: {"labels": parse_label(x["labels"])})
small_validation = small_validation.map(lambda x: {"labels": parse_label(x["labels"])})
small_test = small_test.map(lambda x: {"labels": parse_label(x["labels"])})

"""Show an example from the training dataset to show the plant leaf image and its information."""

ex = small_train[50]
ex

ex_image = ex['image']
ex_image

"""Make sure the validation and test dataset do not contain health conditions that are in the training set."""

# Flatten the lists in the column and get unique values
from itertools import chain
train_unique_names = set(chain.from_iterable(small_train['label_names']))
vali_unique_names = set(chain.from_iterable(small_validation['label_names']))
test_unique_names = set(chain.from_iterable(small_test['label_names']))

# Check for differences
valid_diff = vali_unique_names.difference(train_unique_names)
test_diff = test_unique_names.difference(train_unique_names)

# Print results
print("Labels in validation dataset but not in training dataset:", valid_diff)
print("Labels in test dataset but not in training dataset:", test_diff)

"""Make use the "labels" number is mapped to the label names as ClassLabel class. This is required for the pre-trained ViT model."""

from datasets import Dataset, ClassLabel

class_names = list(train_unique_names)
class_label = ClassLabel(names=class_names)
small_train = small_train.cast_column('labels', class_label)
small_validation = small_validation.cast_column('labels', class_label)
small_test = small_test.cast_column('labels', class_label)

"""Check the train set after all the modification as required."""

# Show the data structure
print(small_train)
print(small_train[0])

"""##Load model and processor

Load the model from the hugging face and set all the necrssary parameters.
"""

from transformers import AutoImageProcessor, AutoModelForImageClassification
from torch.optim import AdamW

# Load the image processor and model
processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
model = AutoModelForImageClassification.from_pretrained(
    "google/vit-base-patch16-224",
    num_labels=len(class_names), # Adjust the number of labels
    ignore_mismatched_sizes=True
)

# Define the optimizer
optimizer = AdamW(model.parameters(), lr=5e-5)  # Learning rate can be adjusted

"""The preprocessing step prepares the raw image data for use with the ViT model. This ensures the images are:

*   Resized to match the model’s expected input dimensions.
*   Normalized to match the model’s training conditions.
*   Converted into tensors for compatibility with the model.
"""

# Preprocess function
def preprocess(example):
    # Ensure pixel_values are tensors
    example["pixel_values"] = processor(example["image"], return_tensors="pt")["pixel_values"].squeeze(0)
    return example

# Apply preprocessing to train and validation sets
train_set = small_train.map(preprocess, batched=False)
val_set = small_validation.map(preprocess, batched=False)
test_set = small_test.map(preprocess, batched=False)

"""**Custom Batching:** The dataset may not directly provide tensors in the required shape, so collate_fn ensures consistent formatting.

**Efficiency:** DataLoader handles data loading in parallel, which is faster than manually iterating over the dataset.

**Reproducibility:** Ensures the same data preprocessing logic is applied consistently across all data splits (training, validation, testing).
"""

import torch
from torch.utils.data import DataLoader

# Create PyTorch DataLoader
def collate_fn(batch):
    pixel_values = torch.stack([torch.tensor(x["pixel_values"]) for x in batch])
    labels = torch.tensor([x["labels"] for x in batch])
    return {"pixel_values": pixel_values, "labels": labels}

train_loader = DataLoader(train_set, batch_size=8, shuffle=True, collate_fn=collate_fn)
val_loader = DataLoader(val_set, batch_size=8, shuffle=False, collate_fn=collate_fn)
test_loader = DataLoader(test_set, batch_size=8, shuffle=False, collate_fn=collate_fn)

"""##Train the model

Run train loop to get train, validation, and test loss for each epoch and generate information for each epoch.
"""

from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import torch

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Initialize lists to store metrics for visualization
train_losses = []
val_losses = []
test_losses = []
test_accuracies = []

# Training loop with integrated visualization
num_epochs = 10
for epoch in range(num_epochs):
    print(f"Epoch {epoch + 1}/{num_epochs}")

    # Training phase
    model.train()
    total_train_loss = 0
    for batch in tqdm(train_loader, desc="Training"):
        optimizer.zero_grad()
        pixel_values = batch["pixel_values"].to(device)
        labels = batch["labels"].to(device)

        outputs = model(pixel_values=pixel_values, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()

        total_train_loss += loss.item()

    avg_train_loss = total_train_loss / len(train_loader)
    train_losses.append(avg_train_loss)

    # Validation phase
    model.eval()
    total_val_loss = 0
    with torch.no_grad():
        for batch in tqdm(val_loader, desc="Validation"):
            pixel_values = batch["pixel_values"].to(device)
            labels = batch["labels"].to(device)

            outputs = model(pixel_values=pixel_values, labels=labels)
            loss = outputs.loss

            total_val_loss += loss.item()

    avg_val_loss = total_val_loss / len(val_loader)
    val_losses.append(avg_val_loss)

    # Test phase
    total_test_loss = 0
    correct = 0
    total = 0
    true_labels = []
    predicted_labels = []
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Testing"):
            pixel_values = batch["pixel_values"].to(device)
            labels = batch["labels"].to(device)

            outputs = model(pixel_values=pixel_values, labels=labels)
            loss = outputs.loss
            total_test_loss += loss.item()

            logits = outputs.logits
            predictions = torch.argmax(logits, dim=-1)

            correct += (predictions == labels).sum().item()
            total += labels.size(0)

            true_labels.extend(labels.cpu().numpy())
            predicted_labels.extend(predictions.cpu().numpy())

    avg_test_loss = total_test_loss / len(test_loader)
    test_accuracy = correct / total
    test_losses.append(avg_test_loss)
    test_accuracies.append(test_accuracy)

    # Log epoch results
    print(f"Epoch {epoch + 1}/{num_epochs}")
    print(f"Train Loss: {avg_train_loss:.4f}")
    print(f"Validation Loss: {avg_val_loss:.4f}")
    print(f"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

"""Visualize the loss trend and show the confusion matrix."""

# Visualization
epochs = range(1, num_epochs + 1)

# Plot training and validation loss
plt.figure(figsize=(8, 6))
plt.plot(epochs, train_losses, label="Training Loss", marker="o")
plt.plot(epochs, val_losses, label="Validation Loss", marker="o")
plt.plot(epochs, test_losses, label="Test Loss", marker="o")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training, Validation and Test Loss")
plt.legend()
plt.grid()
plt.show()

# Plot test accuracy
plt.figure(figsize=(8, 6))
plt.plot(epochs, test_accuracies, label="Test Accuracy", marker="o", color="green")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Test Accuracy")
plt.legend()
plt.grid()
plt.show()

# Plot confusion matrix for the last epoch
cm = confusion_matrix(true_labels, predicted_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)

plt.figure(figsize=(8, 6))
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix")
# Rotate x-axis labels
plt.xticks(rotation=90)
plt.show()

"""Another way to report the result

* Evaluate Model Performance: Use the test dataset (test_loader) to generate predictions and compare them with true labels.
* Classification Report: Summarize the performance of the classification model using metrics like precision, recall, and F1-score.
"""

from sklearn.metrics import classification_report

# Gather all predictions and labels
all_predictions = []
all_labels = []

with torch.no_grad():
    for batch in test_loader:
        pixel_values = batch["pixel_values"].to(device)
        labels = batch["labels"].to(device)

        logits = model(pixel_values=pixel_values).logits
        predictions = torch.argmax(logits, dim=-1)

        all_predictions.extend(predictions.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Generate classification report
print(classification_report(all_labels, all_predictions, target_names=class_names))

"""Show an prediction example from the test set."""

import matplotlib.pyplot as plt

# Define a function to visualize a test example
def show_test_example(model, processor, test_set, index, device):
    # Retrieve the test example
    example = test_set[index]
    image = example["image"]
    true_label = example["labels"]

    # Preprocess the image
    pixel_values = processor(image, return_tensors="pt")["pixel_values"]
    pixel_values = pixel_values.to(device)

    # Make a prediction
    model.eval()
    with torch.no_grad():
        logits = model(pixel_values=pixel_values).logits
        predicted_label = torch.argmax(logits, dim=-1).item()

    # Retrieve label names
    label_names = class_names

    # Display the image with predicted and true labels
    plt.imshow(image)
    plt.title(f"Predicted: {label_names[predicted_label]}\nTrue: {label_names[true_label]}")
    plt.axis("off")
    plt.show()

# Show an example (choose an index from the test set)
show_test_example(model, processor, test_set, index=0, device=device)